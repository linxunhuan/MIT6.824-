# Split Brain
+ 具备容错特性（fault-tolerant）的系统有一个共同的特点
  + MapReduce复制了计算，但是复制这个动作，或者说整个MapReduce被一个单主节点控制
  + GFS以主备（primary-backup）的方式复制数据
    + 它会实际的复制文件内容
    + 但是它也依赖一个单主节点，来确定每一份数据的主拷贝的位置
  + VMware FT，它在一个Primary虚机和一个Backup虚机之间复制计算相关的指令
    + 但是，当其中一个虚机出现故障时，为了能够正确的恢复
    + 需要一个Test-and-Set服务来确认，Primary虚机和Backup虚机只有一个能接管计算任务
+ 这三个例子中，它们都是一个多副本系统（replication system），它们存在一个共性：
  + 它们需要一个单节点来决定，在多个副本中，谁是主（Primary）
    + 使用一个单节点的好处是:
      + 它不可能否认自己
      + 因为只有一个节点，它的决策就是整体的决策
    + 但是使用单节点的缺点是:
      + 它本身又是一个单点故障（Single Point of Failure）
+ 前面介绍的这些系统，它们将系统容错的关键点，转移到了这个单点上
  + 这个单点，会在系统出现局部故障时，选择数据的主拷贝来继续工作
  + 使用单点的原因是:
    + 我们需要避免脑裂（Split-Brain）
--------------------------------------------
+ 假设我们将VMware FT中的Test-and-Set服务构建成多副本的
+ 之前这是一个单点服务，而VMware FT依赖这个Test-and-Set服务来确定Primary虚机
  + 所以，为了提高系统的容错性，我们来构建一个多副本的Test-and-Set服务
+ 现在，我们来假设我们有一个网络，这个网络里面有两个服务器（S1，S2）
  + 这两个服务器都是我们Test-and-Set服务的拷贝
  + 这个网络里面还有两个客户端（C1，C2），它们需要通过Test-and-Set服务确定主节点是谁
  + 在这个例子中，这两个客户端本身就是VMware FT中的Primary和Backup虚拟机
<img src=".\picture\image21.png">

+ 如果这是一个Test-and-Set服务，那么你知道这两个服务器中的数据记录将从0开始
  + 任意一个客户端发送Test-and-Set指令，这个指令会将服务器中的状态设置成1
  + 所以在这个图里面，两个服务器都应该设置成1，然后将旧的值0，返回给客户端
    + 本质上来说，这是一种简化了的锁服务
+ 当一个客户端可以与其中一个服务器通信，但是不能与另一个通信时，有可能出现脑裂的问题
  + 我们假设，客户端发送请求时，它会将请求同时发送给两个服务器
    + 这样，我们就需要考虑，当某个服务器不响应时，客户端该怎么做？
    + 或者说，某个服务器不响应时，整个系统该如何响应？
    + 更具体点，我们假设C1可以访问S1但是不能访问S2，系统该如何响应？
+ 一种情况是，我们必然不想让C1只与S1通信
  + 因为，如果我们只将C1的请求设置给S1，而不设置给S2，会导致S2的数据不一致
  + 所以，我们或许应该规定，对于任何操作，客户端必须总是与两个服务器交互，而不是只与其中一个服务器交互
  + 但是这是一个错误的想法
    + 因为这里根本就没有容错
    + 因为当两个服务器中的一个故障了或者失联了，我们的系统就不能工作了
      + 现在我们有两个服务器，并且两个服务器都必须一致在线，这里的难度比单个服务器更大
      + 如果这种方式不是容错的，我们需要一种行之有效的方法
+ 另一个明显的答案是，如果客户端不能同时与两个服务器交互，那它就与它能连通的那个服务器交互，同时认为另一个服务器已经关机了
  + 这也是一个错误的答案呢
  + 因为，我们的故障场景是:另一个服务器其实还开机着
  + 实际可能是网络线路出现了故障，从而导致C1可以与S1交互，但是不能与S2交互
  + 同时，C2可以与S2交互，但是不能与S1交互
  + 现在我们规定——如果一个客户端连接了两个服务器，为了达到一定的容错性，客户端只与其中一个服务器交互也应该可以正常工作
  + 但是这样就不可避免的出现了这种情况：
    + 假设这根线缆中断了，将网络分为两个部分
<img src=".\picture\image22.png">

+ C1发送Test-and-Set请求给S1，S1将自己的状态设置为1，并返回之前的状态0给C1
<img src=".\picture\image23.png">

+ 这就意味着，C1会认为自己持有锁
  + 如果这是一个VMware FT，C1对应的虚拟机会认为自己可以成为主节点
+ 但是同时，S2里面的状态仍然是0
  + 所以如果现在C2也发送了一个Test-and-Set请求，本来应该发送给两个服务器，但是现在从C2看来，S1不能访问
  + 根据之前定义的规则，那就发送给S2吧
  + 同样的C2也会认为自己持有了锁
  + 如果这个Test-and-Set服务被VMware FT使用，那么这两个VMware 虚机都会认为自己成为了主虚拟机而不需要与另一个虚拟机协商，所以这是一个错误的场景
+ 所以，在这种有两个拷贝副本的配置中，看起来我们只有两种选择：
  + 要么等待两个服务器响应，那么这个时候就没有容错能力
  + 要么只等待一个服务器响应，那么就会进入错误的场景，而这种错误的场景，通常被称为脑裂
+ 这基本是上世纪80年代之前要面临的挑战
+ 但是，当时又的确有多副本系统的要求
  + 例如，控制电话交换机的计算机系统，或者是运行银行系统的计算机系统
  + 当时的人们在构建多副本系统时，需要排除脑裂的可能
  + 这里有两种技术：
    + 第一种是构建一个不可能出现故障的网络
      + 实际上，不可能出现故障的网络一直在我们的身边
      + 电脑中，连接了CPU和内存的线路就是不可能出现故障的网络
      + 如果网络不会出现故障，这样就排除了脑裂的可能
    + 另一种就是人工解决问题，不要引入任何自动完成的操作
      + 默认情况下，客户端总是要等待两个服务器响应
      + 如果只有一个服务器响应，永远不要执行任何操作
      + 相应的，给运维人员打电话，让运维人员去机房检查两个服务器
      + 要么将一台服务器直接关机，要么确认一下其中一台服务器真的关机了，而另一个台还在工作
      + 所以本质上，这里把人作为了一个决策器
# 过半票决（Majority Vote）
+ 人们发现哪怕网络可能出现故障，可能出现分区，实际上是可以正确的实现能够自动完成故障切换的系统
  + 当网络出现故障，将网络分割成两半，网络的两边独自运行，且不能访问对方
  + 这通常被称为**网络分区**
<img src=".\picture\image24.png">

+ 在构建能自动恢复，同时又避免脑裂的多副本系统时，人们发现，关键点在于过半票决（Majority Vote）
  + 这是Raft论文中出现的，用来构建Raft的一个基本概念
+ 过半票决系统的第一步在于，服务器的数量要是奇数，而不是偶数
  + 例如在上图中（只有两个服务器），中间出现故障，那两边就太过对称了
    + 这里被网络故障分隔的两边，它们看起来完全是一样的，它们运行了同样的软件
    + 所以它们也会做相同的事情，这样不太好（会导致脑裂）
  + 但是，如果服务器的数量是奇数的
    + 那么当出现一个网络分割时，两个网络分区将不再对称
  + 然后为了完成任何操作
    + 例如Raft的Leader选举，例如提交一个Log条目
    + 在任何时候为了完成任何操作，你必须凑够过半的服务器来批准相应的操作
      + 这里的过半是指超过服务器总数的一半
      + 直观来看，如果有3个服务器，那么需要2个服务器批准才能完成任何的操作
+ 这里背后的逻辑是:
  + 如果网络存在分区，那么必然不可能有超过一个分区拥有过半数量的服务器
  + 例如，假设总共有三个服务器，如果一个网络分区有一个服务器，那么它不是一个过半的分区
  + 如果一个网络分区有两个服务器，那么另一个分区必然只有一个服务器
  + 因此另一个分区必然不能凑齐过半的服务器，也必然不能完成任何操作
+ 这里有一点需要明确
  + 当我们在说过半的时候，我们是在说所有服务器数量的一半，而不是当前开机服务器数量的一半
+ 在一个过半票决的系统中，如果有3台服务器，那么需要至少2台服务器来完成任意的操作
  + 换个角度来看，这个系统可以接受1个服务器的故障，任意2个服务器都足以完成操作
  + 如果你需要构建一个更加可靠的系统，那么你可以为系统加入更多的服务器
  + 所以，更通用的方程是：
```
如果系统有 2 * F + 1 个服务器，那么系统最多可以接受F个服务器出现故障，仍然可以正常工作
```

+ 通常这也被称为多数投票（quorum）系统，因为3个服务器中的2个，就可以完成多数投票
+ 前面已经提过，有关过半票决系统的一个特性就是:
  + 最多只有一个网络分区会有过半的服务器，所以我们不可能有两个分区可以同时完成操作
  + 这里背后更微妙的点在于
    + 如果你总是需要过半的服务器才能完成任何操作，同时你有一系列的操作需要完成，其中的每一个操作都需要过半的服务器来批准
    + 例如选举Raft的Leader，那么每一个操作对应的过半服务器，必然至少包含一个服务器存在于上一个操作的过半服务器中
    + 也就是说，任意两组过半服务器，至少有一个服务器是重叠的
  + 实际上，相比其他特性，Raft更依赖这个特性来避免脑裂
    + 例如，当一个Raft Leader竞选成功，那么这个Leader必然凑够了过半服务器的选票
    + 而这组过半服务器中，必然与旧Leader的过半服务器有重叠
    + 所以，新的Leader必然知道旧Leader使用的任期号（term number），因为新Leader的过半服务器必然与旧Leader的过半服务器有重叠
    + 而旧Leader的过半服务器中的每一个必然都知道旧Leader的任期号
    + 类似的，任何旧Leader提交的操作，必然存在于过半的Raft服务器中，而任何新Leader的过半服务器中，必然有至少一个服务器包含了旧Leader的所有操作
    + 这是Raft能正确运行的一个重要因素
+ 在过半票决这种思想的支持下，有两个系统基本同时被提出
  + 这两个系统指出，你可以使用这种过半票决系统，从某种程度上来解决之前明显不可能避免的脑裂问题
  + 例如，通过使用3个服务器而不是2个，同时使用过半票决策略
    + 两个系统中的一个叫做Paxos，Raft论文对这个系统做了很多的讨论
    + 另一个叫做ViewStamped Replication（VSR）
# Raft 初探
+ Raft会以库（Library）的形式存在于服务中
+ 一个基于Raft的多副本服务，那么每个服务的副本将会由两部分组成：
  + 应用程序代码
    + 应用程序代码接收RPC或者其他客户端请求
  + Raft库
    + 不同节点的Raft库之间相互合作，来维护多副本之间的操作同步
+ 应用程序通常都有状态，Raft层会帮助应用程序将其状态拷贝到其他副本节点
  + 对于一个Key-Value数据库而言，对应的状态就是Key-Value Table
  + 应用程序往下，就是Raft层
    + 所以，Key-Value数据库需要对Raft层进行函数调用，来传递自己的状态和Raft反馈的信息
<img src=".\picture\image25.png">

+ 同时，如Raft论文中的图2所示，Raft本身也会保持状态
+ Raft的状态中，最重要的就是Raft会记录操作的日志
<img src=".\picture\image26.png">

+ 对于一个拥有三个副本的系统来说，很明显我们会有三个服务器
+ 这三个服务器有完全一样的结构（上面是应用程序层，下面是Raft层）
+ 理想情况下，也会有完全相同的数据分别存在于两层（应用程序层和Raft层）中
+ 除此之外，还有一些客户端，假设我们有了客户端1（C1），客户端2（C2）等等
<img src=".\picture\image27.png">

+ 客户端就是一些外部程序代码，它们想要使用服务
  + 同时它们不知道，也没有必要知道，它们正在与一个多副本服务交互
  + 从客户端的角度来看，这个服务与一个单点服务没有区别
+ 客户端会将请求发送给当前Raft集群中的Leader节点对应的应用程序
  + 这里的请求就是应用程序级别的请求，例如一个访问Key-Value数据库的请求
  + 这些请求可能是Put也可能是Get
    + Put请求带了一个Key和一个Value，将会更新Key-Value数据库中
      + Key对应的Value
    + 而Get向当前服务请求某个Key对应的Value
<img src=".\picture\image28.png">

+ 一旦一个Put请求从客户端发送到了服务端，对于一个单节点的服务来说，应用程序会直接执行这个请求
  + 更新Key-Value表
  + 之后返回对于这个Put请求的响应
+ 但是对于一个基于Raft的多副本服务，就要复杂一些
  + 假设客户端将请求发送给Raft的Leader节点
  + 在服务端程序的内部，应用程序只会将来自客户端的请求对应的操作向下发送到Raft层
  + 并且告知Raft层，请把这个操作提交到多副本的日志（Log）中，并在完成时通知我
<img src=".\picture\image29.png">

+ 之后，Raft节点之间相互交互，直到过半的Raft节点将这个新的操作加入到它们的日志中，也就是说这个操作被过半的Raft节点复制了
<img src=".\picture\image30.png">

+ 当且仅当Raft的Leader过半节点知道了,都有了这个操作的拷贝之后
+ Raft的Leader节点中的Raft层，会向上发送一个通知到应用程序，也就是Key-Value数据库，来说明：
  + 刚刚你提交给我的操作，我已经提交给过半节点副本
  + 并且已经成功拷贝给它们了，现在，你可以真正的执行这个操作了
+ 每个副本节点的Raft层会将相同的操作提交到本地的应用程序层
  + 在本地的应用程序层，会将这个操作更新到自己的状态
  + 所以，理想情况是，所有的副本都将看到相同的操作序列，这些操作序列以相同的顺序出现在Raft到应用程序的upcall中
  + 之后它们以相同的顺序被本地应用程序应用到本地的状态中
  + 假设操作是确定的（比如一个随机数生成操作就不是确定的），所有副本节点的状态，最终将会是完全一样的
  + 图中的Key-Value数据库，就是Raft论文中说的状态（也就是Key-Value数据库的多个副本最终会保持一致）
<img src=".\picture\image31.png">

# Log 同步时序
+ 假设我们有一个客户端，服务器1是当前Raft集群的Leader
+ 同时，我们还有服务器2，服务器3
  + 这张图的纵坐标是时间，越往下时间越长
+ 假设客户端将请求发送给服务器1，这里的客户端请求就是一个简单的请求
  + 例如一个Put请求
+ 之后，服务器1的Raft层会发送一个添加日志（AppendEntries）的RPC到其他两个副本（S2，S3）
  + 现在服务器1会一直等待其他副本节点的响应，一直等到过半节点的响应返回
  + 这里的过半节点包括Leader自己
  + 所以在一个只有3个副本节点的系统中，Leader只需要等待一个其他副本节点
<img src=".\picture\image32.png">

+ 一旦过半的节点返回了响应，这里的过半节点包括了Leader自己
+ 所以在一个只有3个副本的系统中，Leader只需要等待一个其他副本节点返回对于AppendEntries的正确响应
<img src=".\picture\image33.png">

+ 当Leader收到了过半服务器的正确响应，Leader会执行（来自客户端的）请求，得到结果，并将结果返回给客户端
<img src=".\picture\image34.png">

+ 现在Leader知道过半服务器已经添加了Log，可以执行客户端请求，并返回给客户端
+ 但是服务器2还不知道这一点
  + 服务器2只知道：我从Leader那收到了这个请求
    + 但是我不知道这个请求是不是已经被Leader提交（committed）了，**这取决于我的响应是否被Leader收到**
  + 服务器2只知道，它的响应提交给了网络
    + 或许Leader没有收到这个响应，也就不会决定commit这个请求
+ 所以这里还有一个阶段
  + 一旦Leader发现请求被commit之后，它需要将这个消息通知给其他的副本
  + 所以这里有一个额外的消息
<img src=".\picture\image36.png">

+ 与此同时，服务器3可能也会将它的响应返回给Leader，尽管这个响应是有用的，但是这里不需要等待这个响应
<img src=".\picture\image35.png">

# 日志（Raft Log）
为什么Raft系统这么关注Log，Log究竟起了什么作用？
+ Raft系统之所以对Log关注这么多的一个原因是:
  + Log是Leader用来对操作排序的一种手段
+ 对于复制状态机来说，所有副本不仅要执行相同的操作，还需要用相同的顺序执行这些操作
  + 而Log与其他很多事物，共同构成了Leader对接收到的客户端操作分配顺序的机制
  + 比如说，我有10个客户端同时向Leader发出请求，Leader必须对这些请求确定一个顺序，并确保所有其他的副本都遵从这个顺序。实际上，Log是一些按照数字编号的槽位（类似一个数组），槽位的数字表示了Leader选择的顺序。

Log的另一个用途是，在一个（非Leader，也就是Follower）副本收到了操作，但是还没有执行操作时。该副本需要将这个操作存放在某处，直到收到了Leader发送的新的commit号才执行。所以，对于Raft的Follower来说，Log是用来存放临时操作的地方。Follower收到了这些临时的操作，但是还不确定这些操作是否被commit了。我们将会看到，这些操作可能会被丢弃。

Log的另一个用途是用在Leader节点，我（Robert教授）很喜欢这个特性。Leader需要在它的Log中记录操作，因为这些操作可能需要重传给Follower。如果一些Follower由于网络原因或者其他原因短时间离线了或者丢了一些消息，Leader需要能够向Follower重传丢失的Log消息。所以，Leader也需要一个地方来存放客户端请求的拷贝。即使对那些已经commit的请求，为了能够向丢失了相应操作的副本重传，也需要存储在Leader的Log中。

所有节点都需要保存Log还有一个原因，就是它可以帮助重启的服务器恢复状态。你可能的确需要一个故障了的服务器在修复后，能重新加入到Raft集群，要不然你就永远少了一个服务器。比如对于一个3节点的集群来说，如果一个节点故障重启之后不能自动加入，那么当前系统只剩2个节点，那将不能再承受任何故障，所以我们需要能够重新并入故障重启了的服务器。对于一个重启的服务器来说，会使用存储在磁盘中的Log。每个Raft节点都需要将Log写入到它的磁盘中，这样它故障重启之后，Log还能保留。而这个Log会被Raft节点用来从头执行其中的操作进而重建故障前的状态，并继续以这个状态运行。所以，Log也会被用来持久化存储操作，服务器可以依赖这些操作来恢复状态


















