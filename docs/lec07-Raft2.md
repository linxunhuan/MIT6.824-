# 日志恢复
<img src=".\picture\image44.png">

+ 假设下一个任期是6
  + 同时假设S3在任期6被选为Leader
  + 在某个时刻，新Leader S3会发送任期6的第一个AppendEntries RPC，来传输任期6的第一个Log，这个Log应该在槽位13
+ 这里的AppendEntries消息实际上有两条，因为要发给两个Followers
  + 它们包含了客户端发送给Leader的请求
    + 我们现在想将这个请求复制到所有的Followers上
  + 这里的AppendEntries RPC还包含了prevLogIndex字段和prevLogTerm字段
    + 所以Leader在发送AppendEntries消息时，会附带前一个槽位的信息
    + 在我们的场景中，prevLogIndex是前一个槽位的位置，也就是12
    + prevLogTerm是S3上前一个槽位的任期号，也就是5
<img src=".\picture\image45.png">

+ 这样的AppendEntries消息发送给了Followers
  + 而Followers，收到了一个带有若干Log条目的消息，并且是从槽位13开始
  + Followers在写入Log之前，会检查本地的前一个Log条目，是否与Leader发来的有关前一条Log的信息匹配
+ 所以对于S2 它显然是不匹配的
  + S2 在槽位12已经有一个条目，但是它来自任期4，而不是任期5
    + 所以S2将拒绝这个AppendEntries，并返回False给Leader
  + S1在槽位12还没有任何Log，所以S1也将拒绝Leader的这个AppendEntries
+ 到目前位置，一切都还好
  + 我们完全不想看到的是，S2 把这条新的Log添加在槽位13
    + 因为这样会破坏Raft论文中图2所依赖的归纳特性
  + 并且隐藏S2 实际上在槽位12有一条不同的Log的这一事实
+ 为了响应Followers返回的拒绝，Leader会减小对应的nextIndex
  + 所以它现在减小了两个Followers的nextIndex
  + 这一次，Leader发送的AppendEntries消息中，prevLogIndex等于11，prevLogTerm等于3
  + 同时，这次Leader发送的AppendEntries消息包含了prevLogIndex之后的所有条目
    + 也就是S3上槽位12和槽位13的Log
<img src=".\picture\image46.png">

+ 对于S2来说，这次收到的AppendEntries消息中
  + prevLogIndex等于11，prevLogTerm等于3，与自己本地的Log匹配
  + 所以，S2会接受这个消息
+ Raft论文中的图2规定
  + 如果接受一个AppendEntries消息，那么需要首先删除本地相应的Log（如果有的话），再用AppendEntries中的内容替代本地Log
  + 所以，S2会这么做：它会删除本地槽位12的记录，再添加AppendEntries中的Log条目
  + 这个时候，S2的Log与S3保持了一致
<img src=".\picture\image47.png">

+ 但是，S1仍然有问题，因为它的槽位11是空的，所以它不能匹配这次的AppendEntries
  + 它将再次返回False
+ 而Leader会将S1对应的nextIndex变为11，并在AppendEntries消息中带上从槽位11开始之后的Log（也就是槽位11，12，13对应的Log）
  + 并且带上相应的prevLogIndex（10）和prevLogTerm（3）
+ 这次的请求可以被S1接受，并得到肯定的返回。现在它们都有了一致的Log
<img src=".\picture\image48.png">

+ 而Leader在收到了Followers对于AppendEntries的肯定的返回之后，它会增加相应的nextIndex到14
+ 在这里，Leader使用了一种备份机制来探测Followers的Log中，第一个与Leader的Log相同的位置
  + 在获得位置之后，Leader会给Follower发送从这个位置开始的，剩余的全部Log
  + 经过这个过程，所有节点的Log都可以和Leader保持一致
---------------------------------------------
+ 在刚刚的过程中，我们擦除了一些Log条目，比如我们刚刚删除了S2中的槽位12的Log。这个位置是任期4的Log
  + 现在的问题是，为什么Raft系统可以安全的删除这条记录？
    + 毕竟我们在删除这条记录时，某个相关的客户端请求也随之被丢弃了
+ 这条Log条目并没有存在于过半服务器中，因此无论之前的Leader是谁，发送了这条Log，它都没有得到过半服务器的认可
  + 因此旧的Leader不可能commit了这条记录，也就不可能将它应用到应用程序的状态中，进而也就不可能回复给客户端说请求成功了
  + 因为它没有存在于过半服务器中，发送这个请求的客户端没有理由认为这个请求被执行了，也不可能得到一个回复
    + 因为这里有一条规则就是，Leader只会在commit之后回复给客户端
    + 客户端甚至都没有理由相信这个请求被任意服务器收到了
  + 并且，Raft论文中的图2说明，如果客户端发送请求之后一段时间没有收到回复，它应该重新发送请求
    + 所以我们知道，不论这个被丢弃的请求是什么，我们都没有执行它，没有把它包含在任何状态中，并且客户端之后会重新发送这个请求
# 选举约束（Election Restriction）
哪些节点允许成为Leader？
+ 为了保证系统的正确性，并非任意节点都可以成为Leader
  + 不是说第一个选举定时器超时了并触发选举的节点，就一定是Leader
  + Raft对于谁可以成为Leader，谁不能成为Leader是有一些限制的
+ 为了证明并非任意节点都可以成为Leader，我们这里提出一个例子来证伪
  + 在这个反例中，Raft会选择拥有最长Log记录的节点作为Leader
    + 这个规则或许适用于其他系统，但是在Raft中，这条规则不适用
  + 所以，我们这里需要研究的问题是：
    + 为什么不选择拥有最长Log记录的节点作为Leader？
--------------------------------------------------
如果我们这么做了的话，我们需要更改Raft中的投票规则，让选民只投票给拥有更长Log记录的节点
+ 假设我们有3个服务器，现在服务器1（S1）有任期5，6，7的Log，服务器2和服务器3（S2和S3）有任期5，8的Log
<img src=".\picture\image49.png">

这个场景可能出现吗？
+ 让我们回退一些时间，在第二个时间点S1赢得了选举，现在它的任期号是6
  + 它收到了一个客户端请求，在发出AppendEntries之前
  + 它先将请求存放在自己的Log中，然后它就故障了，所以它没能发出任何AppendEntries消息
+ 之后它很快就故障重启了，因为它是之前的Leader，所以会有一场新的选举
  + 这次，它又被选为Leader
  + 然后它收到了一个任期7的客户端请求，将这个请求加在本地Log之后，它又故障了
+ S1故障之后，我们又有了一次新的选举，这时S1已经关机了，不能再参加选举，这次S2被选为Leader
  + 如果S2当选，而S1还在关机状态，S2会使用什么任期号呢？
  + 明显答案是8，但是为什么任期号是8而不是6呢？
+ 尽管没有写在黑板上，但是S1在任期6，7能当选，它必然拥有了过半节点的投票，过半服务器至少包含了S2，S3中的一个节点
  + **当某个节点为候选人投票时，节点应该将候选人的任期号记录在持久化存储中**
  + 所里在这里，S2或者S3或者它们两者都知道任期6和任期7的存在
  + 因此，当S1故障了，它们中至少一个知道当前的任期是8
    + 这里，只有知道了任期8的节点才有可能当选，如果只有一个节点知道，那么这个节点会赢得选举，因为它拥有更高的任期号
    + 如果S2和S3都知道当前任期是8，那么它们两者中的一个会赢得选举
  + 所以，下一个任期必然为8这个事实，依赖于不同任期的过半服务器之间必然有重合这个特点
    + 同时，也依赖任期号会通过RequestVote RPC更新给其他节点，并持久化存储，这样出现故障才不会丢失数据
  + 所以下一个任期号将会是8，S2或者S3会赢得选举
  + 不管是哪一个，新的Leader会继续将客户端请求转换成AppendEntries发给其他节点
<img src=".\picture\image50.png">
-------------------------------------

假设S1重新上线了，并且我们又有了一次新的选举，这时候可以选择S1作为Leader吗？
明显，答案是不可以的
+ 如果S1是Leader，它会通过AppendEntries机制将自己的Log强加给2个Followers
  + 它会发出AppendEntries消息来覆盖S2和S3在任期8的Log
  + 并在S2和S3中写入S1中的任期6和任期7的Log，这样所有的节点的Log才能与S1保持一致
为什么我们不能认可这样的结果呢？
+ 因为S2和S3可以组成过半服务器，所以任期8的Log已经被commit了
  + 对应的请求很可能已经执行了，应用层也很可能发送一个回复给客户端了
  + 所以我们不能删除任期8的Log
  + 因此，S1也就不能成为Leader并将自己的Log强制写入S2和S3
  + 正因为这个原因，**不能在选举的时候直接选择拥有最长Log记录的节点**
----------------------------------------
+ 在Raft论文的5.4.1，Raft有一个稍微复杂的选举限制（Election Restriction）
+ 这个限制要求，在处理别节点发来的RequestVote RPC时，需要做一些检查才能投出赞成票
  + 这里的限制是，节点只能向满足下面条件之一的候选人投出赞成票：
    + 候选人最后一条Log条目的任期号大于本地最后一条Log条目的任期号
    + 或者，候选人最后一条Log条目的任期号等于本地最后一条Log条目的任期号，且候选人的Log记录长度大于等于本地Log记录的长度
+ 如果S2收到了S1的RequestVote RPC，因为S1的最后一条Log条目的任期号是7，而S2的最后一条Log条目的任期号是8
  + 两个限制都不满足，所以S2和S3都不会给S1投赞成票
  + 即使S1的选举定时器的超时时间更短，并且先发出了RequestVote请求，除了它自己，没人会给它投票，所以它只能拿到一个选票，不能凑够过半选票
  + 如果S2或者S3成为了候选人，它们中的另一个都会投出赞成票，因为它们最后的任期号一样，并且它们的Log长度大于等于彼此（满足限制2）
  + 所以S2或者S3中的任意一个都会为另一个投票
# 快速恢复
+ 如果Log有冲突，Leader每次会回退一条Log条目
  + 但是在某些现实的场景中，每次只回退一条Log条目会花费很长很长的时间
  + 所以，现实的场景中，可能一个Follower关机了很长时间，错过了大量的AppendEntries消息
  + 这时，Leader重启了
    + 按照Raft论文中的图2，如果一个Leader重启了，它会将所有Follower的nextIndex设置为Leader本地Log记录的下一个槽位
    + 所以，如果一个Follower关机并错过了1000条Log条目，Leader重启之后，需要每次通过一条RPC来回退一条Log条目来遍历1000条Follower错过的Log记录
+ 假设我们有5个服务器，有1个Leader
  + 这个Leader和另一个Follower困在一个网络分区
  + 但是这个Leader并不知道它已经不再是Leader了
    + 它还是会向它唯一的Follower发送AppendEntries，因为这里没有过半服务器，所以没有一条Log会commit
  + 在另一个有多数服务器的网络分区中，系统选出了新的Leader并继续运行
    + 旧的Leader和它的Follower可能会记录无限多的旧的任期的未commit的Log
  + 当旧的Leader和它的Follower重新加入到集群中时，这些Log需要被删除并覆盖
    + 可能在现实中，这不是那么容易发生
+ 所以，为了能够更快的恢复日志，Raft论文在论文的5.3结尾处，对一种方法有一些模糊的描述,这里的大致思想是:
  + 让Follower返回足够的信息给Leader，这样Leader可以以任期（Term）为单位来回退，而不用每次只回退一条Log条目
  + 所以现在，在恢复Follower的Log时，如果Leader和Follower的Log不匹配，Leader只需要对每个不同的任期发送一条AppendEntries，而不用对每个不同的Log条目发送一条AppendEntries
  + 这只是一种加速策略
-------------------------------------------------
+ 将可能出现的场景分成3类
  + 为了简化，这里只画出一个Leader（S2）和一个Follower（S1）
  + S2将要发送一条任期号为6的AppendEntries消息给Follower
+ 场景1：S1没有任期6的任何Log，因此我们需要回退一整个任期的Log
<img src=".\picture\image51.png">

+ 场景2：S1收到了任期4的旧Leader的多条Log，但是作为新Leader，S2只收到了一条任期4的Log
  + 所以这里，我们需要覆盖S1中有关旧Leader的一些Log
<img src=".\picture\image52.png">

+ 场景3：S1与S2的Log不冲突，但是S1缺失了部分S2中的Log
<img src=".\picture\image53.png">

+ 可以让Follower在回复Leader的AppendEntries消息中，携带3个额外的信息，来加速日志的恢复
  + 这里的回复是指，Follower因为Log信息不匹配，拒绝了Leader的AppendEntries之后的回复
  + 这里的三个信息是指：
    + XTerm：
      + 这个是Follower中与Leader冲突的Log对应的任期号
      + Leader会在prevLogTerm中带上本地Log记录中，前一条Log的任期号
      + 如果Follower在对应位置的任期号不匹配，它会拒绝Leader的AppendEntries消息，并将自己的任期号放在XTerm中
      + 如果Follower在对应位置没有Log，那么这里会返回 -1
    + XIndex：
      + 这个是Follower中，对应任期号为XTerm的第一条Log条目的槽位号
    + XLen：
      + 如果Follower在对应位置没有Log，那么XTerm会返回-1，XLen表示空白的Log槽位数
+ 这些信息是如何在上面3个场景中，帮助Leader快速回退到适当的Log条目位置:
  + 场景1
    + Follower（S1）会返回XTerm=5，XIndex=2
    + Leader（S2）发现自己没有任期5的日志，它会将自己本地记录的，S1的nextIndex设置到XIndex
      + 也就是S1中，任期5的第一条Log对应的槽位号
    + 所以，如果Leader完全没有XTerm的任何Log，那么它应该回退到XIndex对应的位置
      + （这样，Leader发出的下一条AppendEntries就可以一次覆盖S1中所有XTerm对应的Log）
  + 场景2:
    + Follower（S1）会返回XTerm=4，XIndex=1
    + Leader（S2）发现自己其实有任期4的日志，它会将自己本地记录的S1的nextIndex设置到本地在XTerm位置的Log条目后面，也就是槽位2
    + 下一次Leader发出下一条AppendEntries时，就可以一次覆盖S1中槽位2和槽位3对应的Log
  + 场景3:
    + Follower（S1）会返回XTerm=-1，XLen=2
    + 这表示S1中日志太短了，以至于在冲突的位置没有Log条目，Leader应该回退到Follower最后一条Log条目的下一条，也就是槽位2，并从这开始发送AppendEntries消息
    + 槽位2可以从XLen中的数值计算得到
# 持久化（Persistence）
+ 从Raft论文的图2的左上角看到
  + 有些数据被标记为持久化的（Persistent）
  + 有些信息被标记为非持久化的（Volatile）
  + 持久化和非持久化的区别只在服务器重启时重要
+ 当你更改了被标记为持久化的某个数据
  + 服务器应该将更新写入到磁盘，或者其它的持久化存储中
    + 例如一个电池供电的RAM
  + 持久化的存储可以确保当服务器重启时，服务器可以找到相应的数据，并将其加载到内存中
  + 这样可以使得服务器在故障并重启后，继续重启之前的状态
-------------------------------------------
+ 如果一个服务器故障了，那简单直接的方法就是将它从集群中摘除
+ 我们需要具备从集群中摘除服务器，替换一个全新的空的服务器，并让该新服务器在集群内工作的能力
  + 因为如果一些服务器遭受了不可恢复的故障，例如磁盘故障，你绝对需要替换这台服务器
  + 同时，如果磁盘故障了，你也不能指望能从该服务器的磁盘中获得任何有用的信息
  + 所以我们的确需要能够用全新的空的服务器替代现有服务器的能力
+ 实际上，一个常见的故障是断电
  + 断电的时候，整个集群都同时停止运行
  + 这种场景下，如果我们希望我们的服务是容错的， 我们需要能够得到之前状态的拷贝，这样我们才能保持程序继续运行
  + 因此，至少为了处理同时断电的场景，我们不得不让服务器能够将它们的状态存储在某处，这样当供电恢复了之后，还能再次获取这个状态
    + 这里的状态是指，为了**让服务器在断电或者整个集群断电后，能够继续运行所必不可少的内容**
+ 在Raft论文的图2中，有且仅有三个数据是需要持久化存储的
  + 它们分别是Log、currentTerm、votedFor
## Log
+ Log是所有的Log条目
  + 当某个服务器刚刚重启，在它加入到Raft集群之前，它必须要检查并确保这些数据有效的存储在它的磁盘上
  + 服务器必须要有某种方式来发现，自己的确有一些持久化存储的状态，而不是一些无意义的数据
+ Log需要被持久化存储的原因是:
  + 这是唯一记录了应用程序状态的地方
+ Raft论文图2并没有要求我们持久化存储应用程序状态
  + 假如我们运行了一个数据库或者为VMware FT运行了一个Test-and-Set服务
  + 根据Raft论文图2，实际的数据库或者实际的test-set值，并不会被持久化存储，只有Raft的Log被存储了
  + 所以当服务器重启时，唯一能用来重建应用程序状态的信息就是存储在Log中的一系列操作，所以Log必须要被持久化存储
## votedFor
+ currentTerm和votedFor都是用来确保每个任期只有最多一个Leader
  + 在一个故障的场景中，如果一个服务器收到了一个RequestVote请求，并且为服务器1投票了，之后它故障
+ 如果它没有存储它为哪个服务器投过票
  + 当它故障重启之后，收到了来自服务器2的同一个任期的另一个RequestVote请求
    + 那么它还是会投票给服务器2
    + 因为它发现自己的votedFor是空的，因此它认为自己还没投过票
  + 现在这个服务器，在同一个任期内同时为服务器1和服务器2投了票
  + 因为服务器1和服务器2都会为自己投票，它们都会认为自己有过半选票（3票中的2票），那它们都会成为Leader
  + 现在同一个任期里面有了两个Leader
  + 这就是为什么votedFor必须被持久化存储
## currentTerm
+ 如果重启之后我们不知道任期号是什么，很难确保一个任期内只有一个Leader
+ 举个例子
<img src=".\picture\image54.png">

+ S1关机了，S2和S3会尝试选举一个新的Leader
  + 它们需要证据证明，正确的任期号是8，而不是6
  + 如果仅仅是S2和S3为彼此投票，它们不知道当前的任期号，它们只能查看自己的Log，它们或许会认为下一个任期是6（因为Log里的上一个任期是5）
  + 如果它们这么做了，那么它们会从任期6开始添加Log
+ 但是接下来，就会有问题了，因为我们有了两个不同的任期6（另一个在S1中）
  + 这就是为什么currentTerm需要被持久化存储的原因，因为它需要用来保存已经被使用过的任期号
----------------------------
+ 有些数据在Raft论文的图2中标记为非持久化的
+ 为什么服务器重启时，commitIndex、lastApplied、nextIndex、matchIndex，可以被丢弃？
  + 例如，lastApplied表示当前服务器执行到哪一步，如果我们丢弃了它的话，我们需要重复执行Log条目两次
  + （重启前执行过一次，重启后又要再执行一次），这是正确的吗？
  + 为什么可以安全的丢弃lastApplied？
+ 这里综合考虑了Raft的简单性和安全性
  + 之所以这些数据是非持久化存储的，是因为Leader可以通过检查自己的Log和发送给Followers的AppendEntries的结果，来发现哪些内容已经commit了
  + 如果因为断电，所有节点都重启了
    + Leader并不知道哪些内容被commit了，哪些内容被执行了
    + 但是当它发出AppendEntries，并从Followers搜集回信息
      + 它会发现，Followers中有哪些Log与Leader的Log匹配，因此也就可以发现，在重启前，有哪些被commit了
+ 另外，Raft论文的图2假设，应用程序状态会随着重启而消失
  + 所以图2认为，既然Log已经持久化存储了，那么应用程序状态就不必再持久化存储
  + 因为在图2中，Log从系统运行的初始就被持久化存储下来
  + 所以，当Leader重启时，Leader会从第一条Log开始，执行每一条Log条目，并提交给应用程序
  + 所以，重启之后，应用程序可以通过重复执行每一条Log来完全从头构建自己的状态
# 日志快照（Log Snapshot）
+ 在Raft中，Log压缩和快照解决的问题是：
  + 对于一个长期运行的系统，例如运行了几周，几个月甚至几年，如果我们按照Raft论文图2的规则，那么Log会持续增长
    + 最后可能会有数百万条Log，从而需要大量的内存来存储
  + 如果持久化存储在磁盘上，最终会消耗磁盘的大量空间
  + 如果一个服务器重启了，它需要通过重新从头开始执行这数百万条Log来重建自己的状态
    + 当故障重启之后，遍历并执行整个Log的内容可能要花费几个小时来完成
  + 这在某种程度上来说是浪费，因为在重启之前，服务器已经有了一定的应用程序状态
+ 为了应对这种场景，Raft有了快照（Snapshots）的概念
  + 快照背后的思想是，要求应用程序将其状态的拷贝作为一种特殊的Log条目存储下来
+ 假设我们基于Raft构建一个key-value数据库，Log将会包含一系列的Put/Get或者Read/Write请求
  + 假设一条Log包含了一个Put请求，客户端想要将X设置成1，另一条Log想要将X设置成2，下一条将Y设置成7
  + 如果Raft一直执行没有故障，Raft之上的将会是应用程序
    + 在这里，应用程序将会是key-value数据库
    + 它将会维护一个表单，当Raft一个接一个的上传命令时，应用程序会更新它的表单
<img src=".\picture\image55.png">

+ 对于大多数的应用程序来说，应用程序的状态远小于Log的大小
  + Log可能包含大量的重复的记录（例如对于X的重复赋值），这些记录使用了Log中的大量的空间，但是同时却压缩到了key-value表单中的一条记录
  + 在这里，如果存储Log，可能尺寸会非常大，相应的，如果存储key-value表单，这可能比Log尺寸小得多
  + 这就是快照的背后原理
+ 所以，当Raft认为它的Log将会过于庞大
  + 例如大于1MB，10MB或者任意的限制，Raft会要求应用程序在Log的特定位置，对其状态做一个快照
  + 所以，如果Raft要求应用程序做一个快照
    + Raft会从Log中选取一个与快照对应的点，然后要求应用程序在那个点的位置做一个快照
    + **接下来将会丢弃所有那个点之前的Log记录**
    + 我们还需要为快照标注Log的槽位号。在这个图里面，这个快照对应的正好是槽位3
<img src=".\picture\image56.png">

---------------------------------------------
+ 重启的时候，必须让Raft有方法知道磁盘中最近的快照和Log的组合，并将快照传递给应用程序
  + 因为现在我们不能重演所有的Log（部分被删掉了），所以必须要有一种方式来初始化应用程序
  + 所以应用程序不仅需要有能力能生成一个快照
    + 它还需要能够吸纳一个之前创建的快照，并通过它稳定的重建自己的内存
  + 所以，尽管Raft在管理快照，快照的内容实际上是应用程序的属性
  + Raft并不理解快照中有什么，只有应用程序知道
    + 因为快照里面都是应用程序相关的信息
    + 所以重启之后，应用程序需要能够吸纳Raft能找到的最近的一次快照
+ 如果有的Follower的Log较短，在Leader的快照之前就结束
  + 那么除非有一种新的机制，否则那个Follower永远也不可能恢复完整的Log
  + 因为，如果一个Follower只有前两个槽位的Log，Leader不再有槽位3的Log可以通过AppendEntries RPC发给Follower
  + Follower的Log也就不可能补齐至Leader的Log
+ 我们可以通过这种方式来避免这个问题：
  + 如果Leader发现有任何一个Follower的Log落后于Leader要做快照的点，那么Leader就不丢弃快照之前的Log
  + Leader原则上是可以知道Follower的Log位置，然后Leader可以不丢弃所有Follower中最短Log之后的本地Log
+ 之所以这个方法不完美的原因在于，如果一个Follower关机了一周，它也就不能确认Log条目
  + 同时也意味着Leader不能通过快照来减少自己的内存消耗（因为那个Follower的Log长度一直没有更新）
+ 所以，Raft选择的方法是
  + **Leader可以丢弃Follower需要的Log**
  + 所以，我们需要某种机制让AppendEntries能处理某些Follower Log的结尾到Leader Log开始之间丢失的这一段Log
  + 解决方法是（一个新的消息类型）InstallSnapshot RPC
+ 当Follower刚刚恢复，如果它的Log短于Leader通过 AppendEntries RPC发给它的内容
  + 那么它首先会强制Leader回退自己的Log
  + 在某个点，Leader将不能再回退，因为它已经到了自己Log的起点
  + 这时，Leader会将自己的快照发给Follower，之后立即通过AppendEntries将后面的Log发给Follower
# 线性一致（Linearizability）
+ 线性一致等价于强一致
  + 一个服务是线性一致的，那么它表现的就像只有一个服务器，并且服务器没有故障，这个服务器每次执行一个客户端请求，并且没什么奇怪的是事情发生
+ 一个系统的执行历史是一系列的客户端请求，或许这是来自多个客户端的多个请求
  + 如果执行历史整体可以按照一个顺序排列，且排列顺序与客户端请求的实际时间相符合，那么它是线性一致的
  + 当一个客户端发出一个请求，得到一个响应，之后另一个客户端发出了一个请求，也得到了响应
    + 那么这两个请求之间是有顺序的
    + 因为一个在另一个完成之后才开始
  + 一个线性一致的执行历史中的操作是非并发的，也就是时间上不重合的客户端请求与实际执行时间匹配
  + 并且，每一个读操作都看到的是最近一次写入的值
+ 首先，执行历史是对于客户端请求的记录，你可以从系统的输入输出理解这个概念，而不用关心内部是如何实现的
  + 如果一个系统正在工作，我们可以通过输入输出的消息来判断，系统的执行顺序是不是线性一致的
  + 接下来，我们通过两个例子来看，什么是线性一致的，什么不是
--------------------------------------------
+ 线性一致这个概念里面的操作，是从一个点开始，到另一个点结束
  + 所以，这里前一个点对应了客户端发送请求，后一个点对应了收到回复的时间
  + 我们假设，在某个特定的时间，客户端发送了请求，将X设置为1
  + 过了一会，在第二条竖线处，客户端收到了一个回复
    + 客户端在第一条竖线发送请求，在第二条竖线收到回复
<img src=".\picture\image57.png">

+ 过了一会，这个客户端或者其他客户端再发送一个请求，要将X设置为2，并收到了相应的回复
+ 同时，某个客户端发送了一个读X的请求，得到了2
  + 在第一条竖线发送读请求，在这个点，也就是第二条竖线，收到了值是2的响应
+ 同时，还有一个读X的请求，得到值是1的响应
<img src=".\picture\image58.png">

+ 要达到线性一致，我们需要为这里的4个操作生成一个线性一致的顺序
  + 所以我们现在要确定顺序，对于这个顺序，有两个限制条件：
    + 如果一个操作在另一个操作开始前就结束了，那么这个操作必须在执行历史中出现在另一个操作前面
    + 执行历史中，读操作，必须在相应的key的写操作之后
+ 第一个读操作看到的是值2，那么在总的顺序中，这个读必然在第二个写操作后面
  + 同时第二个写必须是离第一个读操作最近一次写
  + 所以，这意味着，在总的顺序中，我们必须先看到对X写2，之后执行读X才能得到2
<img src=".\picture\image59.png">

+ 第二个读X得到的是值1
  + 我们假设X的值最开始不是1，那么会有下图的关系，因为读必须在写之后
  + 第二个读操作必须在第二个写操作之前执行，这样写X为1的操作才能成为第二个读操作最近一次写操作
<img src=".\picture\image60.png">